# Crawler Update: Persistent Folders Per URL

**Date:** 2026-02-25
**Update:** Persistent folder structure with updates instead of timestamped copies

---

## What Changed

The crawler now creates **one folder per domain** and **updates it** when you re-crawl the same site, instead of creating timestamped duplicates.

## Before vs After

### Before (Timestamped Files)
```
Web Crawler/
â””â”€â”€ ai.lilly.com_crawl/
    â”œâ”€â”€ sitemap_20260225_091155.json
    â”œâ”€â”€ sitemap_20260225_094804.json    â† Multiple versions
    â”œâ”€â”€ urls_20260225_091155.json
    â”œâ”€â”€ urls_20260225_094804.json        â† Multiple versions
    â”œâ”€â”€ report_20260225_091155.txt
    â””â”€â”€ report_20260225_094804.txt       â† Multiple versions
```

### After (Single Updated Files) âœ¨
```
Web Crawler/
â””â”€â”€ ai.lilly.com_crawl/
    â”œâ”€â”€ sitemap.json                     â† Always current
    â”œâ”€â”€ urls.json                        â† Always current
    â”œâ”€â”€ report.txt                       â† Always current
    â”œâ”€â”€ index.json / .html / .txt        â† Page files
    â”œâ”€â”€ about.json / .html / .txt
    â””â”€â”€ ...
```

## Benefits

### 1. Clean Structure
- âœ… One file per type (sitemap.json, urls.json, report.txt)
- âœ… No timestamp clutter
- âœ… Easy to find latest data

### 2. Updates Instead of Duplicates
- âœ… Re-crawling the same site updates the folder
- âœ… No manual cleanup needed
- âœ… Always see the latest crawl results

### 3. Smart Detection
- ğŸ”„ If folder exists â†’ Updates files
- âœ¨ If folder is new â†’ Creates new folder

## File Structure

Each crawled domain gets its own folder:

```
Web Crawler/
â”œâ”€â”€ ai.lilly.com_crawl/
â”‚   â”œâ”€â”€ sitemap.json              # Complete sitemap with all pages
â”‚   â”œâ”€â”€ urls.json                 # Categorized URL lists
â”‚   â”œâ”€â”€ report.txt                # Human-readable summary
â”‚   â”œâ”€â”€ index.json / .html / .txt # Homepage
â”‚   â”œâ”€â”€ about.json / .html / .txt # About page
â”‚   â””â”€â”€ ...                       # All other pages
â”‚
â”œâ”€â”€ docs.python.org_crawl/
â”‚   â”œâ”€â”€ sitemap.json
â”‚   â”œâ”€â”€ urls.json
â”‚   â”œâ”€â”€ report.txt
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ portal.company.com_crawl/
    â”œâ”€â”€ sitemap.json
    â”œâ”€â”€ urls.json
    â”œâ”€â”€ report.txt
    â””â”€â”€ ...
```

## Updated Files

### Core Changes
**web_crawler.py** - `save_results()` method:
- âŒ Removed: `timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')`
- âŒ Removed: `sitemap_{timestamp}.json` naming
- âœ… Added: Update detection (checks if files exist)
- âœ… Added: Update/create messages
- âœ… Changed: Files now named `sitemap.json`, `urls.json`, `report.txt`

**Note:** Individual page files already used non-timestamped names, so no changes needed there.

## Behavior Examples

### Example 1: First Crawl (New Domain)
```bash
python3 crawl_authenticated.py https://ai.lilly.com
```

**Output:**
```
âœ¨ Creating new crawl data for ai.lilly.com...
ğŸ“„ Saved complete sitemap: ai.lilly.com_crawl/sitemap.json
ğŸ“„ Saved URL list: ai.lilly.com_crawl/urls.json
ğŸ“„ Saved text report: ai.lilly.com_crawl/report.txt
```

**Folder created:** `Web Crawler/ai.lilly.com_crawl/`

---

### Example 2: Re-crawl (Update Existing)
```bash
# Crawl the same site again
python3 crawl_authenticated.py https://ai.lilly.com
```

**Output:**
```
ğŸ”„ Updating existing crawl data for ai.lilly.com...
ğŸ“„ Saved complete sitemap: ai.lilly.com_crawl/sitemap.json
ğŸ“„ Saved URL list: ai.lilly.com_crawl/urls.json
ğŸ“„ Saved text report: ai.lilly.com_crawl/report.txt
```

**Folder updated:** `Web Crawler/ai.lilly.com_crawl/` (overwrites previous data)

---

### Example 3: Different Domain (New Folder)
```bash
python3 crawl_simple.py https://docs.python.org
```

**Output:**
```
âœ¨ Creating new crawl data for docs.python.org...
ğŸ“„ Saved complete sitemap: docs.python.org_crawl/sitemap.json
```

**New folder created:** `Web Crawler/docs.python.org_crawl/`

## Migration: Cleaning Up Old Files

If you have old timestamped files from previous crawls, you can clean them up:

### Option 1: Manual Cleanup
Delete old timestamped files, keep the newest:
```bash
cd "Web Crawler/ai.lilly.com_crawl"

# Keep newest timestamped files, rename to new format
mv sitemap_20260225_094804.json sitemap.json
mv urls_20260225_094804.json urls.json
mv report_20260225_094804.txt report.txt

# Delete old timestamped versions
rm sitemap_202602*.json  # (if multiple exist)
rm urls_202602*.json
rm report_202602*.txt
```

### Option 2: Fresh Start
Just re-crawl and the new format will be used:
```bash
python3 crawl_authenticated.py https://ai.lilly.com
# New files will be created without timestamps
# Old timestamped files will remain but won't be updated
```

### Option 3: Clean Slate
Remove the entire folder and re-crawl:
```bash
rm -rf ai.lilly.com_crawl/
python3 crawl_authenticated.py https://ai.lilly.com
```

## Timestamp Information

While main files no longer have timestamps in their names, the **crawl timestamp is preserved** inside the files:

**In `urls.json`:**
```json
{
  "root_url": "https://ai.lilly.com",
  "base_domain": "ai.lilly.com",
  "crawled_at": "2026-02-25T09:48:04.635227",  â† Timestamp here
  "summary": { ... }
}
```

**In `report.txt`:**
```
Web Crawl Report
================================================================================

Root URL: https://ai.lilly.com
Base Domain: ai.lilly.com
Crawled: 2026-02-25 09:48:04          â† Timestamp here
```

## Backward Compatibility

- âœ… Old timestamped files still readable (just not generated anymore)
- âœ… Existing folder structure unchanged
- âœ… All crawlers (simple, authenticated, legacy) updated
- âœ… No breaking changes to data format

## Summary

| Aspect | Before | After |
|--------|--------|-------|
| **Main files** | `sitemap_20260225_094804.json` | `sitemap.json` |
| **On re-crawl** | Creates new timestamped files | Updates existing files |
| **Folder per domain** | Yes | Yes |
| **Timestamp info** | In filename | Inside file content |
| **Cleanup needed** | Manual | Automatic (overwrites) |

---

**Status:** âœ… Updated
**Files Modified:** `web_crawler.py` (save_results method)
**Version:** 3.1
**Date:** 2026-02-25
