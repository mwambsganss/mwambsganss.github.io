{
  "url": "https://ai.lilly.com/ai-registry/faq",
  "title": "AI Registry Frequently Asked Questions | ai.lilly.com",
  "description": "",
  "h1": [
    "AI Registry Frequently Asked Questions"
  ],
  "h2": [
    "Have an Idea?"
  ],
  "h3": [],
  "text_content": "AI Registry Frequently Asked Questions | ai.lilly.com\nMenu\nmenu closed\nSearch closed\nAccount closed\nHome\nProducts\nEnterprise-wide\nAvailable to Limited Groups\nStack\nProducts\nEnterprise-wide\nAvailable to Limited Groups\nStack\nAI Registry\nIntake\nProcess\nReports\nFAQs\nModify/Withdraw a Submission\nAI Registry\nIntake\nProcess\nReports\nFAQs\nModify/Withdraw a Submission\nGuidance\nLearning\nFAQ\nRegister AI Idea\nClose\nHome\nProducts\nEnterprise-wide\nAvailable to Limited Groups\nStack\nProducts\nEnterprise-wide\nAvailable to Limited Groups\nStack\nAI Registry\nIntake\nProcess\nReports\nFAQs\nModify/Withdraw a Submission\nAI Registry\nIntake\nProcess\nReports\nFAQs\nModify/Withdraw a Submission\nGuidance\nLearning\nFAQ\nRegister AI Idea\nSuggestions will update as you type\nmagnifying-glass\nAI Registry Frequently Asked Questions\nWhy do we need an AI Registry?\nexpand accordion\nThe AI Registry is a centralized database that captures risk assessment information about all Lilly AI systems.  It enhances transparency, accountability, and compliance with regulatory requirements. It also helps manage risk and ensures that AI projects align with Lilly’s goals and ethical standards.\nWhat types of AI projects should be included in the registry?\nexpand accordion\nSee the\nAI Registry Submission Decision Tree\nWho is responsible for maintaining the AI Registry?\nexpand accordion\nThe Advanced Intelligence team and stakeholders from Architecture, Legal, Cybersecurity, Privacy, and Quality are responsible for maintaining the registry. They ensure that the registry is up-to-date and that all AI projects are adequately documented.\nWho can access the AI Registry?\nexpand accordion\nSubmitters or Custodians can see their use cases by going to the\nLilly Employee Center Portal\nand choosing More > My AI Systems Submitted for Review in the top right.\nAll use cases can be viewed by stakeholders and risk assessors (Prioritization teams, Functional group members, AI Technical Reviewers, Cybersecurity, Legal, Privacy, and Quality).\nAI Use Case Reports\nPortfolio\n:\nHigh-level listing and summaries, and submitted AI Registry items\nOperational\n:\nMetrics for review teams\nIf you need access to additional reports, please send an email to\nai_program_operations_team@lists.lilly.com\n.\nWhen should I submit a use case?\nexpand accordion\nThe AI Policy applies to any existing AI use case not yet reviewed per the\nUsing AI Responsibly at Lilly procedure\nand the\nAI Registry Decision Tree\n.\nFor AI products, chatbots, or tools in use, check the AI Registry\nportfolio reports\nto confirm your use case is properly logged to meet legal and compliance requirements.\nSee the\nAI Registry Submission Decision Tree\nIf you are working with a vendor who is using AI and all of these are true, then no AI Registry use case is required (globally, except China):\nThe AI does not process Lilly data or provide deliverables or services to Lilly (except for business productivity tools*)\nNo model training on behalf of or at the direction of Lilly\nNo integration with Lilly systems\nNo Lilly employees interacting with the system\nMSA / contract contains AI terms (either updated MPT with AI terms or full AI Standard)\n*Business productivity tools\ninclude general-purpose AI assistants like Microsoft Copilot, Grammarly, or similar commercially available tools that vendors may choose to use in their own business operations to improve efficiency, draft communications, or perform routine tasks. Vendors may use these tools at their discretion provided they do not input any Lilly confidential information, proprietary data, or information subject to Lilly's data protection requirements into these systems.\nShould I answer AI Registry questions based on the current state or the intended final use of the solution?\nexpand accordion\nReminder:  Use cases are expected to be submitted to the AI Registry multiple times as the use case proceeds through the\nInnovation Stages\n.\nFill out the registry with (1) the intended purpose of the system (e.g., this system will be used for clinical trial matching and will consume X data at launch) and (2) the current stage of development (e.g., we are operating in a dev environment with dummy (green) data).\nStage = Alpha\nData Classification = Green\nData Processed = None of the above\nAudience = Lilly Employees\nThen when the solution is fully defined and ready for development for production use,\na scope change to your original submission\nmust be submitted\nfor review with updated information.  (See “How do I resubmit a use case?” below)\nStage = Beta\nData Classification = Red\nData Processed = Personal Information (PI), Confidential Information (CI)\nAudience = Patients (Commercial)\nDo you have any guidance or examples of \"good\" AI use case submissions?\nexpand accordion\nCheck out these suggestions:\nAI Submission Guide | Tech HQ\nWhen should I resubmit a use case?\nexpand accordion\nThe AI product has changed scope from the original use case (e.g., If you have a new intended outcome, data collection, increased data classification, expanded the audience, added geographies, or technology changes such as a different vendor, model, or platform)\nYou did not receive guidance from legal.\nThe AI product is advancing Innovation Stage from Pre-Alpha or Alpha to Beta, Early Release, or General Release. Please see\nOur Innovation Stages | Tech HQ\nfor definitions.\nHow do I resubmit a use case?\nexpand accordion\nEither the submitter or custodian should go to\nIntake Form | ai.lilly.com\nand click the Register AI Idea button towards the bottom of that page to get the Intake Form.\nThen on the first question, choose the scope change option and select the system from the drop-down menu. Include as many details as possible about what has changed from the previous submission. Reviewers will focus on what has changed since the previous review.\nWhat reviews are included when I submit my use case?\nexpand accordion\nSee the\nProcess page\nfor a description of the Reviews.\nWho do I contact for each review?\nexpand accordion\nLocal Functional Assessments based on supporting organization,\nclick here to view contacts\n.\nFor Specialized AI Risk Assessments, see below.\nAI Tech Review: Contact Malika Mahoui\nLegal Review: Contact Emma LeMasters\nQuality Review: Contact Rebecca Kitts\nHow long will it take for my use case to be reviewed?\nexpand accordion\nThe review timeline depends on several factors, including:\nThe maturity and completeness of the use case submission\nThe complexity of the AI system\nWhether a new vendor or model is involved\nThe intended users of the AI system (who and where they are)\nThe input data sources\nHow the AI output will be used\nYou can track the status of each review in your AI Registry submission record\nor in the\nLilly AI-Registry Portfolio\nreport listing\n, which shows which reviews are complete and which are in progress.\nPlease note that while you may begin vendor contracting during the review process, your use case is not considered fully approved until all required reviewers have provided their sign-off. Reviews are prioritized first by any approved expedited requests, then by the Prioritization field.\nWe continue to improve the\nAI Registry process\nto make reviews as efficient as possible.\nHow do I cancel or modify an AI use case?\nexpand accordion\nUse the\nSubmit Requests and Report Issues\nlink at the bottom of ai.lilly.com to request modification or cancellation of an AI use case. Include the AIR number, title of the use case, and the submitter’s name.\nHow do I see the status of my AI use case?\nexpand accordion\nTo see the status of your submission, access the\nLilly Employee Center Portal\n, select More in the top right corner, and then select My AI Systems Submitted for Review.\nYou can also search the listing available in the\nPortfolio\n.\nHow do I see the status of a use case where I am not the submitter?\nexpand accordion\nSearch the listing available in the\nPortfolio Reports\n.\nDo I need to register a chat assistant created with Chat in a Box, an Agent created with Copilot studio, or something created with Claude to the AI Registry?\nexpand accordion\nClaude solutions, Chat in a Box, and Copilot Studio Agents are GenAI productivity tools for Lilly employees that typically\ndo not\nneed to be submitted to the AI Registry process. However, specific uses may require registration and review to ensure compliance with legal and information handling requirements.\n✓\nSee the\nAI Registry Submission Decision Tree\n✓ Submit to the AI Registry\nif your AI Assistant will be used for sensitive decisions (e.g., HR recruitment, drug discovery, patient support, regulatory compliance).\n✓ Only share with authorized users\n- Grant access only to users who already have permission to access the underlying data sources. Do not share with unauthorized\nusers.\nWhy are we managing AI risk differently than other System Risks?\nexpand accordion\nMany factors contribute to the heightened concern over AI risks compared to other computer systems. AI has immense potential benefits, but so are the challenges and risks, making it crucial to approach AI development and deployment with caution and robust governance.\nAutonomy and Decision-Making\n: AI systems can make autonomous decisions without human intervention. This can lead to unintended consequences, especially if the AI’s decision-making process is not fully understood or transparent.\nComplexity and Opacity:\nAI models, particularly deep learning systems, are often complex and operate as “black boxes.” This lack of transparency makes it difficult to understand how they arrive at specific decisions, increasing the risk of errors and biases.\nRapid Self-Improvement\n: Advanced AI systems have the potential to improve themselves rapidly. This could lead to scenarios where AI systems surpass human intelligence and control, posing significant risks if not properly managed.\nBias and Discrimination\n: AI systems can perpetuate and even amplify existing biases in the data they are trained on. This can result in unfair and discriminatory outcomes, affecting various aspects of society.\nSecurity and Privacy\n: AI systems can be exploited for malicious purposes, such as spreading misinformation, facilitating cyberattacks, or invading privacy. Their ability to process and analyze vast amounts of data makes them powerful tools that can be misused.\nCan I work in QA and PROD environments after completing the AI Tech review?\nexpand accordion\nNo, before going to QA or Production or processing data through a vendor tool, applicable processes must be complete. This includes all AI Registry reviews and any other company processes that should be undertaken, such as a\nQuality Risk Assessment\n, a\nCybersecurity review\n, a\nPrivacy review\n, and\nWwTP\n. Vendor contracts should include standard AI wording.\nWhat can I do in DEV after completing the AI Tech review for my use case?\nexpand accordion\nOnce the AI Tech review is complete, you may begin development work using only green (non-sensitive, non-production) data in the DEV environment.\nWhat happens if my use case was rejected?\nexpand accordion\nReview the guidance provided by the assessor who rejected the use case.  If you are the submitter or custodian for the use case, you can make updates to the use case by clicking on the Intake form (go to\nAI | ai.lilly.com\nand click on the red “Register AI Idea” button at the top right of the page and choose Intake and click the Register AI Idea button towards the bottom of that page to get the Intake Form). Then on the first question, choose the option describing re-reviewing for a scope change and select your use case. Include as many details as possible about what has changed from the previous submission. Reviewers will focus on what has changed since the previous review.\nIn addition, submissions that have been Rejected or Deferred will be reviewed by the Tech Innovation Pipeline team for Innovation Potential.\nWhere should I go to submit a new tech innovation idea?\nexpand accordion\nThe\nTech Innovation Pipeline (TIP)\nand\nAI Registry (AIR)\nare now combined into one streamlined\nTech@Lilly Innovation Portfolio\n. You can explore insights in the\nunified dashboard\n.\nHave an Idea?\nIntegrating AI into our business is a team effort.\nAll AI use cases must be registered and approved.\nRegister AI Idea\nchats-fill\nQuestions? Chat now!\nSubmit Requests and Report Issues\nUsing AI Responsibly at Lilly\nContact Us\nLilly AI Guidance Assist\nChatbot\nX\nHi, I’m Lilly Assist, the Eli Lilly chatbot. I was created to answer your questions about Lilly AI.\nWhat may I help you with today?\nAvoid sharing personal information in this chat. Remember, AI-generated content may not always be accurate.\nGet started with our quick prompts, or ask your own question below.\nI’m new to AI. How do I get started?\nDo we have any AI tools that can generate images?\nAm I allowed to use ChatGPT at work?\narrow-right",
  "links_found": 10,
  "depth": 1,
  "crawled_at": "2026-02-25T10:12:44.149181"
}