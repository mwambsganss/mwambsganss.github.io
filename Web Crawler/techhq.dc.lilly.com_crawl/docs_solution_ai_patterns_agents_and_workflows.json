{
  "url": "https://techhq.dc.lilly.com/docs/solution/ai/patterns/agents_and_workflows",
  "title": "Workflows | Tech HQ",
  "description": "Last Updated: July 25, 2025",
  "h1": [
    "Workflows",
    "What Are Agents and Agentic Systems",
    "Agents and Workflows: Choosing the Right Approach",
    "Workflow Patterns and Future Directions",
    "Conceptual Hierarchy",
    "References"
  ],
  "h2": [
    "Tool Calling‚Äã",
    "From Tools to Agents‚Äã",
    "Agentic AI Systems‚Äã",
    "Building Blocks of an Agentic System‚Äã",
    "When to Use Workflows vs. Agents‚Äã",
    "Understanding Workflow Patterns‚Äã",
    "Workflow: Prompt Chaining‚Äã",
    "Workflow: Routing‚Äã",
    "Workflow: Parallelization‚Äã",
    "Workflow: Orchestrator-Workers‚Äã",
    "Workflow: Evaluator-Optimizer‚Äã",
    "Looking Ahead: Agentic Patterns‚Äã"
  ],
  "h3": [
    "Use Workflows When:‚Äã",
    "Use Agents When:‚Äã",
    "Complexity-Performance Tradeoff‚Äã"
  ],
  "text_content": "Workflows | Tech HQ\nSkip to main content\nTech HQ\nInnovate\nPlan\nSolution\nAccess\nLearn\nContribute\nUpdates\nLillyFlow\nüß© Solution Overview\nü§ñ AI & Intelligent Agents\nEcosystem\nPatterns\nQuantum Computing\nAgentic\nWorkflows\nBuilding Agentic Patterns\nContext Engineering\nDeep Agents\nDeep Research\nModel Foundry\nProtocols\nPositioning\nExamples\nCoding Tools\nStandards\nAI Submission Guide Template\nüóÑÔ∏è AI & Intelligent Agents BLT\nü§ñ Agentic AI\nüß≠ Conversational AI\nüß≠ Knowledge Bases\nüß≠ Multimodal AI\nüß≠ Translation Services\nüè¢ Business Enablement\n‚òÅÔ∏è Cloud & Infrastructure\nüîê Cybersecurity\nüìä Data & Analytics\nüõ†Ô∏è Engineering Enablement\nüõ∞Ô∏è Observability & Reliability\nüöÄ Team Productivity\nüé® User Experience & Design\nü§ñ AI & Intelligent Agents\nPatterns\nWorkflows\nOn this page\nWorkflows\nDocument Information\nLast Updated:\nJuly 25, 2025\nOwner:\nBrian Lewis\nPoint of Contact:\nAli Kharazmi\nContributors and Reviewers:\nArchit Kaila, Haitham Maya, Malika Mahoui\nIn this article we explore the architectural patterns of AI agents and workflows, examining how LLMs can be orchestrated\nto perform complex tasks through tool calling, reasoning, and various execution strategies.\nTool Calling\n‚Äã\nFunction calling enables LLMs to emit structured JSON \"calls\" to predefined functions (i.e., tools or APIs), rather than\nfree-form text, allowing seamless integration with external systems. A key principle of tool calling is that the model\ndecides when to use a tool based on the input's relevance.\nTool Binding\nWhat is 2 multiplied by 3?\nLLM with Tool Binding\nTool Definition\nPayload:\narguments: {'a':2, 'b':3}\ntool_name: multiply\ndef multiply(a,b):\nreturn a*b\nThis mechanism underpins modern agent frameworks by giving LLMs the ability to decide autonomously which tool to invoke\nand with what parameters, and even to chain multiple calls in service of complex tasks.\nFrom Tools to Agents\n‚Äã\nWhile tool calling provides LLMs with the ability to interact with external systems, agents represent a more\nsophisticated integration where these capabilities are combined with reasoning, planning, and autonomy. Agents leverage\ntool calling as a fundamental mechanism but extend it with additional capabilities.\n1.Natural language\n2.JSON call\n'function_name' + args\n3.Execute tool/api\n4.Return results\n5.Synthesize reply\nUser Prompt\nLLM (with function calling)\nDefined Functions/Tools\nFunction Executor\nFinal Response\nWhat Are Agents and Agentic Systems\nAgentic AI Systems\n‚Äã\nAgentic AI systems can autonomously perform tasks, make decisions and solve complex problems based on context and\nobjectives with minimal human supervision. These systems combine the flexibility of Gen-AI based reasoning (agents) with\nthe precision of traditional software engineering (tools) to plan, adapt and react.\nThe key components of agents are:\nAutonomy\n: Agents act independently within a defined scope, making their own decisions without continuous human\nintervention.\nGoal-Oriented\n: They break down high-level objectives into ordered sub-tasks, ensuring systematic progress toward\nspecific outcomes.\nTool Integration\n: Agents invoke external functions‚ÄîAPIs, databases, custom code‚Äîto execute real-world actions\nrather than just generate text.\nMemory & Context\n: By storing short- and long-term memories, they track past interactions and maintain continuity\nacross complex workflows.\nFeedback Loop\n: Agents evaluate the results of each action, learn from failures, and iteratively refine their\napproach using reinforcement learning or iterative planning.\nDecision-Making Framework\n: They employ reasoning strategies (e.g., chain-of-thought, rule-based logic) to choose\nwhich tools to use and how to sequence tasks for optimal performance.\nAction\nFeedback\nHuman\nLLM Call\nEnvironment\nStop\nBuilding Blocks of an Agentic System\n‚Äã\nAt the core of agentic systems is an LLM enhanced with capabilities like retrieval, tools, and memory. These models can\nactively decide what to search, which tools to use, and what to remember. When implementing, focus on tailoring these\naugmentations to your use case and providing a clear, well-documented interface for your LLM.\nAgents and Workflows: Choosing the Right Approach\nThere is an important architectural distinction between workflows and agents:\nWorkflows\n: Systems where LLMs and tools are orchestrated through predefined code paths. The logic is hard-coded,\nand execution follows a fixed sequence.\nAgents\n: Systems where LLMs dynamically determine their own actions and tool usage. They maintain control over task\nexecution, deciding how to proceed based on goals and context.\nWhen to Use Workflows vs. Agents\n‚Äã\nWhen building LLM-powered applications, it's important to choose the simplest solution that meets your requirements.\nThis decision framework can help determine the appropriate approach:\nUse Workflows When:\n‚Äã\nTasks are well-defined with predictable steps\nConsistency and reliability are critical priorities\nYou need tight control over execution paths\nPerformance and latency requirements are strict\nCost efficiency is a primary concern\nThe problem space is well-understood and stable\nUse Agents When:\n‚Äã\nTasks require dynamic decision-making and adaptation\nProblems are complex with unpredictable paths to solutions\nFlexibility is more important than deterministic behavior\nThe environment or requirements change frequently\nTasks benefit from autonomous exploration of solutions\nMultiple tools need to be orchestrated based on context\nComplexity-Performance Tradeoff\n‚Äã\nAgentic systems often trade latency and cost for better task performance. This tradeoff should be carefully considered:\nStart Simple\n: For many applications, optimizing single LLM calls with retrieval and in-context examples is\nsufficient\nAdd Structure\n: When more control is needed, implement workflows with predefined paths\nIntroduce Agency\n: Only move to fully agentic systems when the benefits of flexibility and autonomous\ndecision-making outweigh the increased complexity, latency, and cost\nThe diagram below illustrates this progression from simple to complex approaches:\nLower complexity\nLower latency\nLower cost\nHigher flexibility\nBetter at complex tasks\nMore autonomous\nSimple LLM Calls\nwith Retrieval\nStructured\nWorkflows\nAutonomous\nAgents\nPerformance\nTradeoffs\nWorkflow Patterns and Future Directions\nUnderstanding Workflow Patterns\n‚Äã\nWorkflow patterns are specific, reusable architectural approaches that solve common orchestration challenges. These\npatterns have emerged from practical experience implementing LLM-based systems and provide proven templates for\ndifferent use cases.\nEach pattern offers distinct advantages for particular scenarios, with tradeoffs in complexity, flexibility, and\nperformance. Understanding these patterns helps developers select the most appropriate architecture for their specific\nrequirements.\nWorkflow: Prompt Chaining\n‚Äã\nWhat it is\n: Breaks a complex task into a linear sequence of LLM calls, where each step depends on the output of\nthe previous one. Optional checks (\"gates\") can be added to validate intermediate results before continuing.\nUse Case\n: Tasks that naturally decompose into smaller, ordered subtasks.\nGoal\n: Improve accuracy by simplifying each step (with increased latency).\nExamples\n:\nWrite marketing copy ‚Üí translate it.\nDraft document outline ‚Üí verify ‚Üí write document.\nOutput 1\nPass\nFail\nOutput 2\nIn\nLLM Call 1\nGate\nLLM Call 2\nExit\nLLM Call 3\nOut\nWorkflow: Routing\n‚Äã\nWhat it is\n: An initial LLM (or classifier) decides what kind of input it's dealing with, then sends it to a\nspecialized follow-up process with tailored prompts, models, or tools.\nUse Case\n: Handling different input types that require different processing logic or prompts.\nGoal\n: Avoid one-size-fits-all prompts and optimize each case for performance.\nExamples\n:\nRoute support tickets by topic (refund, tech, billing).\nSend easy queries to small models, complex ones to powerful models.\nIn\nLLM Call Router\nLLM Call 1\nLLM Call 2\nLLM Call 3\nOut\nWorkflow: Parallelization\n‚Äã\nWhat it is\n: Executes multiple LLM tasks simultaneously. Two major types:\nSectioning\ndivides the task into parts that can be handled independently.\nVoting\nruns the same task multiple times to compare and combine outputs.\nUse Case\n: Tasks where subtasks are independent or benefit from diversity in answers.\nGoal\n: Reduce latency or improve quality through redundancy and diversity.\nExamples\n:\nSectioning\n: One model handles query; another filters for safety.\nVoting\n: Multiple LLMs review code or content and compare flags.\nIn\nLLM Call 2\nLLM Call 1\nLLM Call 3\nAggregator\nOut\nWorkflow: Orchestrator-Workers\n‚Äã\nWhat it is\n: A central LLM (the \"orchestrator\") dynamically analyzes the input, decides what subtasks are needed,\nand delegates each one to a \"worker\" LLM. The orchestrator then combines the results into a final answer.\nUse Case\n: Complex or open-ended tasks where required steps vary case by case.\nGoal\n: Introduce flexibility in how tasks are broken down and executed.\nExamples\n:\nModify code across multiple unpredictable files.\nAggregate and analyze info from multiple sources for research.\nIn\nOrchestrator\nLLM Call 1\nLLM Call 2\nLLM Call 3\nSynthesizer\nOut\nWorkflow: Evaluator-Optimizer\n‚Äã\nWhat it is\n: One LLM generates an initial output, and another LLM (or the same one in a different role) evaluates\nthat output and provides feedback or suggestions. This loop can repeat until the result meets defined quality\nstandards.\nUse Case\n: Tasks that benefit from refinement and where clear quality signals are available.\nGoal\n: Use iteration and self-critique to improve outputs.\nExamples\n:\nRefine literary translation based on nuance critiques.\nPerform multi-round research and validation for deeper coverage.\nSolution\nAccepted\nRejected + Feedback\nIn\nLLM Call Generator\nLLM Call Evaluator\nOut\nLooking Ahead: Agentic Patterns\n‚Äã\nWhile this article has focused primarily on workflow patterns, the agent side of the hierarchy deserves equal attention.\nIn our upcoming article \"Agentic Patterns,\" we will explore in depth the different types of agent architectures:\nSingle Agents\n: Autonomous systems that operate independently, using various reasoning and decision-making\nstrategies to accomplish tasks\nMulti-Agents\n: Collaborative systems where multiple agents work together, often specializing in different aspects\nof a problem\nThese agent patterns represent the next frontier in LLM applications, enabling even more sophisticated reasoning,\nplanning, and problem-solving capabilities. By understanding both workflow patterns and agent patterns, developers can\nmake informed decisions about which architectural approaches best suit their specific use cases.\nConceptual Hierarchy\nThe diagram below illustrates the conceptual hierarchy between tool calling, agents, and workflow patterns:\nTool Calling\nAgents\nWorkflows\nSingle Agents\nMulti Agents\nWorkflow Patterns\nPrompt Chaining\nRouting\nParallelization\nOrchestrator-Workers\nEvaluator-Optimizer\nReferences\nLangChain Tool Calling Concepts\nLangChain Workflow\nLangChain Tool Calling How-To\nOpenAI Function Calling Guide\nPrompting Guide: Function Calling\nAnthropic: Building Effective Agents\nLangGraph Multi-agent systems\nWas this helpful?\nTags:\nagent-workflows\nEdit this page\nPrevious\nAgentic\nNext\nBuilding Agentic Patterns\nTool Calling\nFrom Tools to Agents\nAgentic AI Systems\nBuilding Blocks of an Agentic System\nWhen to Use Workflows vs. Agents\nUse Workflows When:\nUse Agents When:\nComplexity-Performance Tradeoff\nUnderstanding Workflow Patterns\nWorkflow: Prompt Chaining\nWorkflow: Routing\nWorkflow: Parallelization\nWorkflow: Orchestrator-Workers\nWorkflow: Evaluator-Optimizer\nLooking Ahead: Agentic Patterns\nCommunity\nEBA Viva Engage\nEBA SharePoint\nQuestions?\nReach us on Viva Engage!\nCopyright ¬© 2026 Eli Lilly and Company",
  "links_found": 9,
  "depth": 3,
  "crawled_at": "2026-02-25T10:08:05.617641"
}