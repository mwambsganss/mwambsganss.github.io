Title: Model Layer | Tech HQ
URL: https://techhq.dc.lilly.com/docs/solution/ai/ecosystem/model_layer
Description: Last Updated: July 25, 2025

Model Layer | Tech HQ
Skip to main content
Tech HQ
Innovate
Plan
Solution
Access
Learn
Contribute
Updates
LillyFlow
ğŸ§© Solution Overview
ğŸ¤– AI & Intelligent Agents
Ecosystem
Experience Layer
AI Layer
Data Layer
Model Layer
Patterns
Positioning
Examples
Coding Tools
Standards
AI Submission Guide Template
ğŸ—„ï¸ AI & Intelligent Agents BLT
ğŸ¤– Agentic AI
ğŸ§­ Conversational AI
ğŸ§­ Knowledge Bases
ğŸ§­ Multimodal AI
ğŸ§­ Translation Services
ğŸ¢ Business Enablement
â˜ï¸ Cloud & Infrastructure
ğŸ” Cybersecurity
ğŸ“Š Data & Analytics
ğŸ› ï¸ Engineering Enablement
ğŸ›°ï¸ Observability & Reliability
ğŸš€ Team Productivity
ğŸ¨ User Experience & Design
ğŸ¤– AI & Intelligent Agents
Ecosystem
Model Layer
On this page
Model Layer
Document Information
Last Updated:
July 25, 2025
Owner:
Brian Lewis
Point of Contact:
Ali Kharazmi
Contributors and Reviewers:
Archit Kaila, Haitham Maya, Malika Mahoui
Definition
â€‹
Leading commercial and strategic capabilities for probabilistic approaches, providing common controls, MLOps, and LLMOps features, underpinning AI-enabled products; reserved for domain experts. This layer manages the lifecycle of machine learning and large language models with specialized tools and governance for expert users.
Components
â€‹
Model Eval
AI
Live Guardrails
SPE
Red Teaming
Scale AI
Detection Guardrails
Scale AI
CATS
Kubernetes
Kubed
Kubernetes
MagTrain
MagTrain
LLM Gateway
LiteLLM
Model Hub
Model hub
Model Training
AWB
Model Lab
AWB
Model Gateway
Model
Infrastructure
Operations
Model
â€‹
LLM Gateway
LiteLLM
Model Hub
Model hub
Model Training
AWB
Model Lab
AWB
Model Gateway
LLM Gateway
â€‹
Unified SDK raw model access to foundational LLMs with load balancing, guardrail checks, and usage monitoring
Platform
:
LLM Gateway
Model Training
â€‹
Scalable service leveraging distributed compute & accelerators, with hyperparameter tracking and tuning functionality for training large AI models
Platform
:
Model Training
Model Gateway
â€‹
Inference serving layer for any Lilly fine-tuned ML model, giving standardized endpoints, authentication, and blue/green deployment support
Platform
:
Model Gateway
Model Lab
â€‹
Sandbox, Air-Gapped, governed workspace (notebooks + managed compute) where data scientists explore data, fine-tune models, and run experiments
Infrastructure Components
â€‹
CATS
â€‹
Cloud infrastructure to deploy Lilly internal applications
Platform
:
CATS
Kubed
â€‹
Cloud infrastructure to deploy Lilly external applications
Platform
:
Kubed
MagTrain
â€‹
Dedicated GPU/HPC cluster with secure data enclaves and ML-optimized storage, orchestrated for heavy model-training jobs
Operation Component
â€‹
Model Eval
â€‹
Continuous evaluation and benchmarking of models against curated pharma tasks & public datasets, tracking drift, bias, and performance regressions over versions
Live Guardrails
â€‹
Cortex-Guard: In-line governance hooks that intercept prompts, responses, and data flows to enforce policy checks, PII masking, and security controls before content reaches end users
Red Teaming
â€‹
Structured adversarial testing that bombards models and agents with malicious or edge-case inputs to surface vulnerabilities and measure robustness
Detection Guardrails
â€‹
Batch service that scans data for AE/PC, toxicity, bias, or policy violations, issuing explainable reports and remediation guidance
Was this helpful?
Edit this page
Previous
Data Layer
Next
Patterns
Definition
Components
Model
LLM Gateway
Model Training
Model Gateway
Model Lab
Infrastructure Components
CATS
Kubed
MagTrain
Operation Component
Model Eval
Live Guardrails
Red Teaming
Detection Guardrails
Community
EBA Viva Engage
EBA SharePoint
Questions?
Reach us on Viva Engage!
Copyright Â© 2026 Eli Lilly and Company