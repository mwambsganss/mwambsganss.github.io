{
  "url": "https://techhq.dc.lilly.com/docs/solution/ai/patterns/model_foundry",
  "title": "Model Foundry | Tech HQ",
  "description": "Last Updated: July 25, 2025",
  "h1": [
    "Model Foundry"
  ],
  "h2": [
    "Bringing Model Development to Production‚Äã",
    "Current State Initiative‚Äã",
    "Current State SLURM Architecture‚Äã",
    "Current Migration Underway‚Äã",
    "Next Steps‚Äã",
    "MLflow vs Weights & Biases: Feature Comparison‚Äã",
    "comprehenxive list of citations\"‚Äã"
  ],
  "h3": [
    "Key Takeaways‚Äã",
    "üìö Citations‚Äã"
  ],
  "text_content": "Model Foundry | Tech HQ\nSkip to main content\nTech HQ\nInnovate\nPlan\nSolution\nAccess\nLearn\nContribute\nUpdates\nLillyFlow\nüß© Solution Overview\nü§ñ AI & Intelligent Agents\nEcosystem\nPatterns\nQuantum Computing\nAgentic\nWorkflows\nBuilding Agentic Patterns\nContext Engineering\nDeep Agents\nDeep Research\nModel Foundry\nProtocols\nPositioning\nExamples\nCoding Tools\nStandards\nAI Submission Guide Template\nüóÑÔ∏è AI & Intelligent Agents BLT\nü§ñ Agentic AI\nüß≠ Conversational AI\nüß≠ Knowledge Bases\nüß≠ Multimodal AI\nüß≠ Translation Services\nüè¢ Business Enablement\n‚òÅÔ∏è Cloud & Infrastructure\nüîê Cybersecurity\nüìä Data & Analytics\nüõ†Ô∏è Engineering Enablement\nüõ∞Ô∏è Observability & Reliability\nüöÄ Team Productivity\nüé® User Experience & Design\nü§ñ AI & Intelligent Agents\nPatterns\nModel Foundry\nOn this page\nModel Foundry\nDocument Information\nLast Updated:\nJuly 25, 2025\nOwner:\nBrian Lewis\nPoint of Contact:\nAli Kharazmi\nContributors and Reviewers:\nArchit Kaila, Haitham Maya, Malika Mahoui\nBringing Model Development to Production\n‚Äã\nHypervisor for AI teams to leverage advanced compute for model training, serving, and advanced AI workloads\nAccelerate time-to-value for ML investments by reducing infrastructure and engineering load on ML teams\nEnhanced visibility, collaboration, and reproducibility across model development lifecycle\nIncrease advanced compute utilization rates through optimized resource management\nTrain & Deploy\nConsume Models\nUse Resources\nOrchestrates\nMagtrain Infrastructure\nMagtrain Compute\nTraining & Inference\nObject Storage\nModels & Artifacts\nAI Practitioners\nData Scientists & ML\nEngineers\nApplications\nAI-Powered Services\nModel Foundry\nPlatform\nCurrent State Initiative\n‚Äã\nThe current implementation uses Magtrain with Slurm:\nCentralized job scheduling: Resource allocation, job scheduling, and distribution of workloads\nQueue-based management: Structured queue system that tracks pending, running, and completed tasks\nCommand Line Interface (CLI): Interaction through standardized CLI commands (i.e., sbatch, squeue, scancel) for job submission and monitoring\nStorage access: Direct integration with shared storage systems\nCurrent State SLURM Architecture\n‚Äã\nData Scientists & ML\nEngineers\nJob submission &\nmonitoring\nCommand Line Interface\nsbatch, squeue, scancel\nSLURM Controller\nJob scheduling & resource\nallocation\nJob Queue\nPending, running,\ncompleted jobs\nMagtrain GPU Cluster\nGPU compute nodes\nShared Storage\nData & model artifacts\nCurrent Migration Underway\n‚Äã\nMigration from Slurm to Run.ai, which provides more robust GPU orchestration and resource management capabilities.\nNext Steps\n‚Äã\nEvaluate MLflow or Weights & Biases for model training and serving capabilities, leveraging learnings from LRL's model gateway implementation.\nPlatform Resources:\nMLflow:\nhttps://mlflow.org/\nWeights & Biases:\nhttps://wandb.ai/site\nEvaluation Focus Areas:\nThe assessment will cover ML lifecycle management, experiment tracking, model deployment, and visualization capabilities. Key considerations include:\nComparative analysis of platform capabilities and limitations\nCompatibility and integration potential between the two platforms\nFeature mapping for core ML operations (tracking, registry, deployment)\nData scientist user experience and workflow optimization\nAlignment with existing infrastructure and team requirements\nMLflow vs Weights & Biases: Feature Comparison\n‚Äã\nFeature Category\nMLflow\nWeights & Biases\nOverview\nOpen-source, vendor-neutral platform from Databricks. Emphasizes flexibility and on-premise deployment\nCommercial cloud-based platform. Emphasizes ease-of-use, collaboration, and rich hosted interface\nExperiment Tracking\nSimple API with basic UI. Supports autologging for major frameworks. Requires server setup for teams\nPolished web UI with real-time sync. Plug-and-play setup with rich media support and live updates\nModel Registry & Artifacts\nBuilt-in registry with lifecycle management (staging, production). Works with any storage backend\nIntegrated registry with versioned artifacts. Tightly coupled with tracking and includes collaborative dashboards\nHyperparameter Tuning\nNo built-in HPO. Integrates with external tools (Optuna, Ray Tune, HyperOpt)\nFirst-class Sweeps feature with grid, random, and Bayesian optimization. Automated visualization of results\nVisualization & Reporting\nBasic web UI with simple charts and run comparisons. Limited visualization capabilities\nRich interactive platform with custom charts, embedding projector, and shareable Reports for storytelling\nDeployment & Serving\nBuilt-in model serving as REST APIs. Supports local, cloud, and edge deployments\nNo native serving capabilities. Focuses on handoff to external deployment infrastructure\nPipeline Orchestration\nNot an orchestration framework. Requires external tools (Airflow, Kubeflow) for pipelines\nNot a pipeline engine. Uses external tools for workflow orchestration beyond HPO sweeps\nEcosystem & Integrations\nExtensive framework support (TensorFlow, PyTorch, XGBoost, etc.). Language-agnostic with REST API\nBroad SDK support with official integrations. Includes MLflow importer for migration compatibility\nCollaboration & Team Features\nBasic collaboration via shared server. No built-in user management or access controls\nTeam-centric design with RBAC, SSO, audit logs, and real-time collaboration features\nPricing & Licensing\nCompletely free and open-source. No licensing costs\nTiered SaaS model: Free tier available, Pro (~$50/mo), Enterprise (custom pricing)\nData Scientist Workflow\nDIY approach requiring manual setup. Straightforward but needs infrastructure management\nPlug-and-play experience with instant web interface. More visual and collaborative workflow\nKey Takeaways\n‚Äã\nMLflow\nexcels for organizations wanting vendor-neutral, self-hosted solutions with full control over infrastructure\nWeights & Biases\nexcels for teams prioritizing collaboration, rich visualization, and managed cloud experience\nBoth platforms are\ncompatible\n- W&B can import MLflow experiments, and MLflow can sync with W&B sweeps\nChoice depends on priorities:\nopenness vs convenience\n,\nrequired features\n, and\nbudget constraints\ncomprehenxive list of citations\"\n‚Äã\nüìö Citations\n‚Äã\nMLflow Official Documentation\nCovers all components of MLflow: Tracking, Projects, Models, and Registry.\nMLflow GitHub Repository\nOpen-source repository for the MLflow project including examples and issues.\nW&B Official Website\nOverview of Weights & Biases features, pricing, and platform capabilities.\nW&B Importers Documentation\nInstructions for importing MLflow runs and artifacts into W&B.\nW&B Sweeps Documentation\nGuide to W&B's hyperparameter tuning and optimization tool.\nMLflow Autologging Guide\nDetails supported libraries and how autologging works.\nMLflow Model Registry Guide\nExplanation of versioning, model stages, and approvals.\nWeights & Biases Model Registry\nDescribes model versioning, tracking lineage, and deployment handoff.\nW&B Reports\nHow to build and share collaborative dashboards using W&B Reports.\nW&B Launch\nRun training jobs on cloud infrastructure like SageMaker, GCP, etc.\nW&B SDK Integrations\nCovers TensorFlow, PyTorch, scikit-learn, Hugging Face, and more.\nZenML Comparison: MLflow vs W&B\nSide-by-side breakdown of features and limitations.\nWeights & Biases Pricing\nDetails on Free, Pro, and Enterprise tiers and their capabilities.\nW&B Artifacts Guide\nVersioning and managing datasets, model weights, and results.\nDatabricks MLflow Overview\nManaged MLflow on Databricks including deployment and monitoring features.\nWas this helpful?\nEdit this page\nPrevious\nDeep Research\nNext\nProtocols\nBringing Model Development to Production\nCurrent State Initiative\nCurrent State SLURM Architecture\nCurrent Migration Underway\nNext Steps\nMLflow vs Weights & Biases: Feature Comparison\nKey Takeaways\ncomprehenxive list of citations\"\nüìö Citations\nCommunity\nEBA Viva Engage\nEBA SharePoint\nQuestions?\nReach us on Viva Engage!\nCopyright ¬© 2026 Eli Lilly and Company",
  "links_found": 5,
  "depth": 3,
  "crawled_at": "2026-02-25T10:08:12.812353"
}