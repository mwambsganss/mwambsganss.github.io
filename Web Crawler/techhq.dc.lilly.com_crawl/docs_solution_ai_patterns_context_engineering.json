{
  "url": "https://techhq.dc.lilly.com/docs/solution/ai/patterns/context_engineering",
  "title": "Context Engineering | Tech HQ",
  "description": "Last Updated: July 25, 2025",
  "h1": [
    "Context Engineering"
  ],
  "h2": [
    "Context Engineering Overview‚Äã",
    "Types of Context‚Äã",
    "Context Challenges‚Äã",
    "Strategies for Agent Context Engineering‚Äã",
    "Compress‚Äã",
    "Isolate‚Äã",
    "Context Engineering with LangGraph‚Äã",
    "References‚Äã"
  ],
  "h3": [
    "Write‚Äã",
    "Select‚Äã",
    "Write Context‚Äã",
    "Select Context‚Äã",
    "Compress Context‚Äã",
    "Isolate Context‚Äã"
  ],
  "text_content": "Context Engineering | Tech HQ\nSkip to main content\nTech HQ\nInnovate\nPlan\nSolution\nAccess\nLearn\nContribute\nUpdates\nLillyFlow\nüß© Solution Overview\nü§ñ AI & Intelligent Agents\nEcosystem\nPatterns\nQuantum Computing\nAgentic\nWorkflows\nBuilding Agentic Patterns\nContext Engineering\nDeep Agents\nDeep Research\nModel Foundry\nProtocols\nPositioning\nExamples\nCoding Tools\nStandards\nAI Submission Guide Template\nüóÑÔ∏è AI & Intelligent Agents BLT\nü§ñ Agentic AI\nüß≠ Conversational AI\nüß≠ Knowledge Bases\nüß≠ Multimodal AI\nüß≠ Translation Services\nüè¢ Business Enablement\n‚òÅÔ∏è Cloud & Infrastructure\nüîê Cybersecurity\nüìä Data & Analytics\nüõ†Ô∏è Engineering Enablement\nüõ∞Ô∏è Observability & Reliability\nüöÄ Team Productivity\nüé® User Experience & Design\nü§ñ AI & Intelligent Agents\nPatterns\nContext Engineering\nOn this page\nContext Engineering\nDocument Information\nLast Updated:\nJuly 25, 2025\nOwner:\nBrian Lewis\nPoint of Contact:\nAli Kharazmi\nContributors and Reviewers:\nArchit Kaila, Haitham Maya, Malika Mahoui\nAgents need context to perform tasks. Context engineering is the art and science of filling the context window with just the right information at each step of an agent's trajectory.\nContext Engineering Overview\n‚Äã\nCore\nIsolate\nSplit Across Sub-agents\nSeparation of Concern\nCode Environment\nSeparation\nRuntime State Object\nCompress\nSummarizing\nRecursive/Hierarchical\nSummarization\nAgent to Agent\nSummarization\nTrimming\nRemove Older Messages\nFrom List\nSelect\nRead State Object/Scratchpad\nSelecting Memory\nPull Narrow Sets of File\nKnowledge Graph for\nMemory Indexing\nWrite\nScratchpad\nTool Calling\nWrite to scratchpad file\nRuntime State Object\nMemory\nSelf Generated Memories\nAcross Sessions\nContext Engineering\nWrite\nSelect\nCompress\nIsolate\nTypes of Context\n‚Äã\nContext engineering serves as an umbrella that applies across a few different context types:\nInstructions\n‚Äì prompts, memories, few-shot examples, tool descriptions, etc.\nKnowledge\n‚Äì facts, memories, etc.\nTools\n‚Äì feedback from tool calls\nContext Challenges\n‚Äã\nLong-running tasks and accumulating feedback from tool calls mean that agents often utilize a large number of tokens. This can degrade performance and opens up the door for hallucinations.\nStrategies for Agent Context Engineering\n‚Äã\nThese strategies can be categorized into 4 buckets:\nWrite\n‚Äì Saving context outside the context window to help an agent perform tasks\nSelect\n‚Äì Pulling relevant context into the context window when needed\nCompress\n‚Äì Retaining only the essential tokens required to perform tasks\nIsolate\n‚Äì Splitting context into separate components to optimize agent performance\nWrite\n‚Äã\nJust as humans take notes, agents can use \"scratchpads\" to persist information outside the context window. This approach saves critical information that remains accessible throughout task execution.\nImplementation Methods:\nSingle Session:\nFile-based storage\n‚Äì A tool call that writes information to a persistent file\nRuntime state\n‚Äì A field in a state object that persists during the session\nCross-Session:\n3.\nLong-term memory\n‚Äì Persistent storage that remembers information across multiple sessions (e.g., Windsurf, Cursor, ChatGPT)\nSelect\n‚Äã\nContext selection depends on how the scratchpad is implemented. If it's a tool, agents access it via tool calls. If it's part of the agent's runtime state, developers decide which parts of the state are exposed at each step, allowing more control over what context is visible during reasoning.\nMemory Usage\n‚Äã\nWhen agents have memory, they must also select which memories to use:\nEpisodic memories\nprovide few-shot examples of prior behavior.\nProcedural memories\nstore instructions to guide actions.\nSemantic memories\nstore factual knowledge relevant to tasks.\nSelecting the right memory improves performance and personalization.\nChallenges and Solutions\n‚Äã\nA key challenge is ensuring relevant memories are selected:\nMany code agents use fixed files (e.g.,\nCLAUDE.md\n,\nCursor's rules files\n) for consistent behavior.\nAgents with large memory stores (especially semantic memory) require advanced retrieval strategies.\nEmbeddings and knowledge graphs help with retrieval, but issues like irrelevant memory injection can still happen. For instance,\nChatGPT\nhas mistakenly inserted private user data into responses, raising concerns over context control and trust.\nCompress\n‚Äã\nAgent interactions can span hundreds of turns with token-heavy tool calls, requiring compression strategies to manage context efficiently.\nSummarization:\nUses LLMs to distill essential information from lengthy interactions\nClaude Code's\n\"auto-compact\" feature demonstrates this approach, summarizing full trajectories when context exceeds 95%\nCan employ recursive or hierarchical summarization strategies\nUseful for post-processing token-heavy tool calls (e.g., search results)\nApplied at agent-agent boundaries to reduce tokens during knowledge hand-off\nContext Trimming:\nFilters or \"prunes\" context using hard-coded heuristics rather than LLM processing\nExamples include removing older messages from conversation history\nMore deterministic than summarization but less intelligent about content relevance\nIsolate\n‚Äã\nContext isolation splits information across separate components to optimize agent performance.\nMulti-Agent:\nSplit context across sub-agents with specific tools and instructions\nOpenAI Swarm\nlibrary enables separation of concerns for specialized sub-tasks\nEach agent maintains its own context window\nSandboxed Environments:\nCode execution in isolated environments (e.g.,\nHuggingFace CodeAgent\n)\nSelected context from tool calls passed back to LLM\nPrevents context contamination between execution and reasoning\nState Objects:\nRuntime state schemas with selective field exposure\nContext written to specific fields, only relevant portions exposed to LLM\nEnables controlled context access without full sandboxing\nContext Engineering with LangGraph\n‚Äã\nWrite Context\n‚Äã\nLangGraph\nsupports short-term (thread-scoped) and long-term memory. Short-term memory uses checkpoints as a scratchpad, letting agents write and retrieve state across steps.\nSelect Context\n‚Äã\nAt each step, agents can:\nAccess short-term state\nto retrieve intermediate data\nQuery long-term memory\nusing different retrieval methods\nCompress Context\n‚Äã\nLangGraph\nlets you control context by passing a\nstate\nobject between nodes. A common method is using a message list and periodically\nsummarizing\nor\ntrimming it\nwith built-in tools.\nIsolate Context\n‚Äã\nLangGraph\nuses a structured\nstate\nobject where you define a schema. This lets you store tool outputs or other data in specific fields, keeping them isolated from the LLM until needed.\nReferences\n‚Äã\nContext Engineering for Agents\n- arXiv preprint. Available at:\nhttps://arxiv.org/pdf/2507.13334\nContext Engineering for Agents\n- LangChain Blog. Available at:\nhttps://blog.langchain.com/context-engineering-for-agents/\nWas this helpful?\nEdit this page\nPrevious\nBuilding Agentic Patterns\nNext\nDeep Agents\nContext Engineering Overview\nTypes of Context\nContext Challenges\nStrategies for Agent Context Engineering\nWrite\nSelect\nCompress\nIsolate\nContext Engineering with LangGraph\nWrite Context\nSelect Context\nCompress Context\nIsolate Context\nReferences\nCommunity\nEBA Viva Engage\nEBA SharePoint\nQuestions?\nReach us on Viva Engage!\nCopyright ¬© 2026 Eli Lilly and Company",
  "links_found": 8,
  "depth": 3,
  "crawled_at": "2026-02-25T10:08:07.921053"
}